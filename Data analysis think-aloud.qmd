---
author: "Sarah Bez"
title: "Data analysis think-aloud"
format: html
editor: visual
---

Libraries

```{r}
library(readxl)
library(lubridate)
library(skimr)
library(tidyverse)
library(ggplot2)
library(psych)
library(DescTools)
library(lpSolve)
library(irr)
library(viridisLite)
library(viridis)
library(devtools)
library(hrbrthemes)
library(ggalt)
library(gt)
library(heuristicsmineR)
```

# Data import: excel sheets from MAXQDA and validation due to MAXQDA issues

neu händisch erstellt von Fabian

```{r}
data_maxqda_komplett_fabian_validating <- read_excel("data/Codierte Segmente komplett_Export Fabian.xlsx")%>%
  select(Dokumentgruppe, Dokumentname, Anfang, Ende, Code)%>%
    filter(Dokumentgruppe == "Konsens")%>% # filtern, was man jeweils braucht 
  mutate(start = ymd_hms(ymd("2000-01-01") + hms(Anfang)), # Datum im Prinzip frei wählbar
                 end = ymd_hms(ymd("2000-01-01") + hms(Ende)), 
                 turnID = 1:n(),
                 code = Code)%>%
  select(-Anfang, -Ende, -Code, -turnID) # nur für Validierung beider Datensätze


```

kurz nach Ende Konsensratings Runde 1 erstellt (MAXQDA 2018, Florian)

```{r}
data_maxqda_komplett_florian_validating <- read_excel("data/MAXQDA 2018 Codings 3_fertig_Runde1.xlsx")%>%
  select(Dokumentgruppe, Dokumentname, Anfang, Ende, Code)%>%
    filter(Dokumentgruppe == "Konsens")%>% # filtern, was man jeweils braucht 
  mutate(start = ymd_hms(ymd("2000-01-01") + hms(Anfang)), # Datum im Prinzip frei wählbar
                 end = ymd_hms(ymd("2000-01-01") + hms(Ende)), 
                 turnID = 1:n(),
                 code = Code)%>%
  select(-Anfang, -Ende, -Code, -turnID) # nur für Validierung beider Datensätze 

```

Check beider df

```{r}
anti_join(data_maxqda_komplett_fabian_validating, data_maxqda_komplett_florian_validating)

anti_join(data_maxqda_komplett_florian_validating, data_maxqda_komplett_fabian_validating)

```

beide sind quasi gleich. Was bei Fabian zusätzilch noch drin ist, waren alte Kodierungen ganz am Anfang von Kategorien, die dann nicht weiterverfolgt wurden. turnID muss beachtet werden (das macht auch Sinn)

event df, bei dem Rundungsproblem noch nicht berücksichtig ist

```{r}
data_konsens_event <- read_excel("data/MAXQDA 2018 Codings 3_fertig_Runde1.xlsx")%>%
  select(Dokumentgruppe, Dokumentname, Anfang, Ende, Code)%>%
    filter(Dokumentgruppe == "Konsens")%>% # filtern, was man jeweils braucht 
  mutate(start = ymd_hms(ymd("2000-01-01") + hms(Anfang)), # Datum im Prinzip frei wählbar
                 end = ymd_hms(ymd("2000-01-01") + hms(Ende)), 
                 turnID = 1:n(),
                 code = Code)%>%
  select(-Anfang, -Ende, -Code)
```

# Wrangling Rundungsproblem timestamps mit lubridate

```{r}
data_konsens_event_corrected <- 
read_excel("data/Codierte Segmente komplett_Export Fabian.xlsx")%>%
  select(Dokumentgruppe, Dokumentname, Anfang, Ende, Code)%>%
  filter(Dokumentgruppe == "Konsens")%>%
  mutate(Anfang_2 = str_sub(Anfang, -1),
         Ende_2 = str_sub(Ende, -1))%>%
    mutate(start_1 = ymd_hms(ymd("2000-01-01") + hms(Anfang)), # Datum im Prinzip frei wählbar
                 end_1 = ymd_hms(ymd("2000-01-01") + hms(Ende)), 
                 turnID = 1:n(),
                 code = Code)%>%
  mutate(start = case_when(Anfang_2 > 4 ~ (ymd_hms(start_1) + seconds(1)), TRUE~ ymd_hms(start_1)))%>%
  mutate(end = case_when(Ende_2 > 4 ~ (ymd_hms(end_1) + seconds(1)), TRUE ~ ymd_hms(end_1)))%>%
  select(Dokumentname, Dokumentgruppe, code, turnID, start, end)
  

  
```

# events to turns

```{r}
data_timesampling <- data_konsens_event_corrected%>%
  mutate(time = map2(start, end, seq, by = "1 sec"))%>%
  unnest(cols = time)%>%
  select(-start, -end, -turnID)%>%
  group_by(time, Dokumentname, Dokumentgruppe)%>%
  summarise(code = toString(code))%>%
  ungroup()%>%
  splitstackshape::cSplit_e("code", sep = ",", type = "character", drop = F, fill = 0)%>%
  as_tibble()%>%
  arrange(Dokumentname) 


```

# Check überlappende Kodierungen

## Grafikcodes

dürfte nicht so stark sein. Kategorien: \* AGG: Aufgabengrafik \* KLG: Klassengrafik \* VLG: Verlaufsgrafik \* KG: Kompetenzgrafik \* TG: Themengrafik

Überlappungen: AGG - KLG AGG - VLG AGG - KG AGG - TG KLG - VLG KLG - KG KLG - TG VLG - KG VLG - TG KG - TG

```{r}
data_timesampling%>%
  select(Dokumentname, code_AGG, code_KLG, code_VLG, code_KG, code_TG, code_SU)%>%
  mutate(agg_klg = ifelse(code_AGG == 1 & code_KLG == 1 & code_SU == 0, 1, 0),
         agg_vlg = ifelse(code_AGG == 1 & code_VLG == 1 & code_SU == 0, 1, 0),
         agg_kg = ifelse(code_AGG == 1 & code_KG == 1 & code_SU == 0, 1, 0),
         agg_tg = ifelse(code_AGG == 1 & code_TG == 1 & code_SU == 0, 1, 0),
         klg_vlg = ifelse(code_KLG == 1 & code_VLG == 1 & code_SU == 0, 1, 0),
         klg_kg = ifelse(code_KLG == 1 & code_KG == 1 & code_SU == 0, 1, 0),
         klg_tg = ifelse(code_KLG == 1 & code_TG == 1 & code_SU == 0, 1, 0),
         vlg_kg = ifelse(code_VLG == 1 & code_KG == 1 & code_SU == 0, 1, 0),
         vlg_tg = ifelse(code_VLG == 1 & code_TG == 1 & code_SU == 0, 1, 0),
         kg_tg = ifelse(code_KG == 1 & code_TG == 1 & code_SU == 0, 1, 0))%>%
  #group_by(Dokumentname)%>%
  summarize(agg_klg = sum(agg_klg),
            agg_vlg = sum(agg_vlg),
            agg_kg = sum(agg_kg),
            agg_tg = sum(agg_tg),
            klg_vlg = sum(klg_vlg),
            klg_kg = sum(klg_kg), 
            klg_tg = sum(klg_tg), 
            vlg_kg = sum(vlg_kg),
            vlg_tg = sum(vlg_tg),
            kg_tg = sum(kg_tg))%>%
  gt(.)
  
```

# nähere Inspektion von agg_klg, agg_vlg, klg_vlg; Rest vernachlässigbar bei 48 Videos

```{r}
data_timesampling%>%
  select(Dokumentname, code_AGG, code_KLG, code_VLG, code_KG, code_TG, code_SU)%>%
  mutate(agg_klg = ifelse(code_AGG == 1 & code_KLG == 1 & code_SU == 0, 1, 0),
         agg_vlg = ifelse(code_AGG == 1 & code_VLG == 1 & code_SU == 0, 1, 0),
         agg_kg = ifelse(code_AGG == 1 & code_KG == 1 & code_SU == 0, 1, 0),
         agg_tg = ifelse(code_AGG == 1 & code_TG == 1 & code_SU == 0, 1, 0),
         klg_vlg = ifelse(code_KLG == 1 & code_VLG == 1 & code_SU == 0, 1, 0),
         klg_kg = ifelse(code_KLG == 1 & code_KG == 1 & code_SU == 0, 1, 0),
         klg_tg = ifelse(code_KLG == 1 & code_TG == 1 & code_SU == 0, 1, 0),
         vlg_kg = ifelse(code_VLG == 1 & code_KG == 1 & code_SU == 0, 1, 0),
         vlg_tg = ifelse(code_VLG == 1 & code_TG == 1 & code_SU == 0, 1, 0),
         kg_tg = ifelse(code_KG == 1 & code_TG == 1 & code_SU == 0, 1, 0))%>%
  group_by(Dokumentname)%>%
  summarize(agg_klg = sum(agg_klg),
            agg_vlg = sum(agg_vlg),
            #agg_kg = sum(agg_kg),
            #agg_tg = sum(agg_tg),
            klg_vlg = sum(klg_vlg))%>%
            #klg_kg = sum(klg_kg), 
            #klg_tg = sum(klg_tg), 
            #vlg_kg = sum(vlg_kg),
            #vlg_tg = sum(vlg_tg),
            #kg_tg = sum(kg_tg))%>%
  filter(agg_klg > 3 | agg_vlg > 3 | klg_vlg > 3 )%>%
  gt(.)

```

7 (ca 1/7) Lehrkräfte über benchmark 3 Sekunden, davon 5 Kodierungn \> 7 Sek. Am stärksten: Überschneidungen von klg und agg, macht auch inhaltlich Sinn. Vorerst zurückgestellt.

## Inhaltscodes

Kategorien: RG: Rezeption FA: Fehleranalyse AB: Abgleich Eigeneinschätzung HM: Handlungsmaßnahmen

Überlappungen: RG - FA RG - AB RG - HM FA - AB FA - HM AB - HM

```{r}
data_timesampling%>%
  select(Dokumentname, code_RG, code_FA, code_AB, code_HM, code_SU)%>%
  mutate(rg_fa = ifelse(code_RG == 1 & code_FA== 1 & code_SU == 0, 1, 0),
         rg_ab = ifelse(code_RG == 1 & code_AB== 1 & code_SU == 0, 1, 0), 
         rg_hm = ifelse(code_RG == 1 & code_HM== 1 & code_SU == 0, 1, 0),
         fa_ab = ifelse(code_FA == 1 & code_AB== 1 & code_SU == 0, 1, 0), 
         fa_hm = ifelse(code_FA == 1 & code_HM== 1 & code_SU == 0, 1, 0),
         ab_hm = ifelse(code_AB == 1 & code_HM== 1 & code_SU == 0, 1, 0))%>%
#group_by(Dokumentname)%>%
  summarize(rg_fa = sum(rg_fa), 
            rg_ab = sum(rg_ab),
            rg_hm = sum(rg_hm),
            fa_ab = sum(fa_ab), 
            fa_hm = sum(fa_hm),
            ab_hm = sum(ab_hm))
```

das scheint alles substanziell.

### sortiert nach Überlappungen:

```{r}
data_timesampling%>%
  select(Dokumentname, code_RG, code_FA, code_AB, code_HM, code_SU)%>%
  mutate(rg_fa = ifelse(code_RG == 1 & code_FA== 1 & code_SU == 0, 1, 0),
         rg_ab = ifelse(code_RG == 1 & code_AB== 1 & code_SU == 0, 1, 0), 
         rg_hm = ifelse(code_RG == 1 & code_HM== 1 & code_SU == 0, 1, 0),
         fa_ab = ifelse(code_FA == 1 & code_AB== 1 & code_SU == 0, 1, 0), 
         fa_hm = ifelse(code_FA == 1 & code_HM== 1 & code_SU == 0, 1, 0),
         ab_hm = ifelse(code_AB == 1 & code_HM== 1 & code_SU == 0, 1, 0))%>%
group_by(Dokumentname)%>%
  summarize(rg_fa = sum(rg_fa), 
            rg_ab = sum(rg_ab),
            rg_hm = sum(rg_hm),
            fa_ab = sum(fa_ab), 
            fa_hm = sum(fa_hm),
            ab_hm = sum(ab_hm))%>%
  filter(rg_fa > 3 | rg_ab > 3 | rg_hm > 3 | fa_ab > 3 | fa_hm > 3 | ab_hm > 3)%>%
  select(-Dokumentname)%>%
  pivot_longer(everything(), names_to = "codes", values_to = "sek")%>%
  ggplot(aes(codes, sek)) + geom_boxplot() + geom_jitter()
```

```{r}
data_timesampling%>%
  select(Dokumentname, code_RG, code_FA, code_AB, code_HM, code_SU)%>%
  mutate(rg_fa = ifelse(code_RG == 1 & code_FA== 1 & code_SU == 0, 1, 0),
         rg_ab = ifelse(code_RG == 1 & code_AB== 1 & code_SU == 0, 1, 0), 
         rg_hm = ifelse(code_RG == 1 & code_HM== 1 & code_SU == 0, 1, 0),
         fa_ab = ifelse(code_FA == 1 & code_AB== 1 & code_SU == 0, 1, 0), 
         fa_hm = ifelse(code_FA == 1 & code_HM== 1 & code_SU == 0, 1, 0),
         ab_hm = ifelse(code_AB == 1 & code_HM== 1 & code_SU == 0, 1, 0))%>%
group_by(Dokumentname)%>%
  summarize(rg_fa = sum(rg_fa), 
            rg_ab = sum(rg_ab),
            rg_hm = sum(rg_hm),
            fa_ab = sum(fa_ab), 
            fa_hm = sum(fa_hm),
            ab_hm = sum(ab_hm))%>%
  filter(rg_fa > 3 | rg_ab > 3 | rg_hm > 3 | fa_ab > 3 | fa_hm > 3 | ab_hm > 3)%>%
  select(-Dokumentname)%>%
  pivot_longer(everything(), names_to = "codes", values_to = "sek")%>%
  ggplot(aes(codes, sek)) + geom_boxplot() + geom_jitter() + coord_cartesian(ylim = c(0, 50)) + theme_minimal()
```

### sortiert nach Lehrpersonen

```{r}
data_timesampling%>%
  select(Dokumentname, code_RG, code_FA, code_AB, code_HM, code_SU)%>%
  mutate(rg_fa = ifelse(code_RG == 1 & code_FA== 1 & code_SU == 0, 1, 0),
         rg_ab = ifelse(code_RG == 1 & code_AB== 1 & code_SU == 0, 1, 0), 
         rg_hm = ifelse(code_RG == 1 & code_HM== 1 & code_SU == 0, 1, 0),
         fa_ab = ifelse(code_FA == 1 & code_AB== 1 & code_SU == 0, 1, 0), 
         fa_hm = ifelse(code_FA == 1 & code_HM== 1 & code_SU == 0, 1, 0),
         ab_hm = ifelse(code_AB == 1 & code_HM== 1 & code_SU == 0, 1, 0))%>%
group_by(Dokumentname)%>%
  summarize(rg_fa = sum(rg_fa), 
            rg_ab = sum(rg_ab),
            rg_hm = sum(rg_hm),
            fa_ab = sum(fa_ab), 
            fa_hm = sum(fa_hm),
            ab_hm = sum(ab_hm))%>%
  filter(rg_fa > 3 | rg_ab > 3 | rg_hm > 3 | fa_ab > 3 | fa_hm > 3 | ab_hm > 3)%>%
  pivot_longer(!Dokumentname, names_to = "codes", values_to = "sek")%>%
  ggplot(aes(sek, Dokumentname, color = codes)) + geom_jitter() + theme_minimal() + coord_cartesian(xlim = c(0, 100))
```

nicht ganz so informativ wie gedacht ...

# Datengrundlage nur offener think-aloud timesampling

```{r}
data_timesampling_ta_o <- data_timesampling%>%
  select(Dokumentname, code_RG, code_FA, code_AB, code_HM, code_SU, code_TA_O, time)%>%
  filter(code_TA_O == 1)
```

# Exploring HeuristicsMiner bzw. bupaverse

Libraries und Beispieldatensätze

```{r}
library(heuristicsmineR)
library(eventdataR)
library(bupaR)
library(petrinetR)
library(psmineR)


# testcode
data(patients)

# Dependency graph / matrix
dependency_matrix(patients)
# Causal graph / Heuristics net
causal_net(patients)

View(patients)

```

auch in den patients daten gibt es "Lücken", d.h. die events gehen nicht direkt ineinander über.

## data wrangling: event logs

filtering nur offener Think-aloud Teil (TA_O): alles, was vor dem ende des (letzten vergebenen) TA_O event liegt

```{r}
# wenn Lehrpersonen vor dem Stimulus angefangen haben, laut zu denken, gibt es mehrere TA_O-Kodierungen. Daher filterung nach dem max von TA_O innerhalb von Personen
# 
max_TA_O <- data_konsens_event_corrected%>% 
  select(-Dokumentgruppe)%>%
  filter(code %in% c("TA_O"))%>%
  group_by(Dokumentname)%>%
  summarize(max_TA_O = max(ymd_hms(end)))

konsens_event_ta_o <- data_konsens_event_corrected%>% 
  select(-Dokumentgruppe)%>%
  filter(code %in% c("RG", "AB", "FA", "HM"))%>%
  left_join(., max_TA_O, by = "Dokumentname")%>%
  filter(end <= max_TA_O)

```

creating event logs

```{r}

eventlog_test <- konsens_event_ta_o%>% 
  rename(complete = end)%>%
  convert_timestamps(columns = c("start", "complete"), format = ymd_hms)%>%
  mutate(test = c(1))%>% # man braucht das auf jeden Fall, ohne resource id kann man das objekt nicht generieren, daher dummy var 
   activitylog(case_id = "Dokumentname",
                activity_id = "code",
                timestamps = c("start", "complete"), 
               resource_id = "test")%>% #d
  to_eventlog() # von eventlog zu activitylog geht recht schnell, es gibt auch die inverse Funktion 


```

-   resource id?
-   case_id = Grafiken und "Zuordnung" insgesamt?

Causal net und petri net

```{r}

# Dependency graph / matrix
dependency_matrix(eventlog_test)

# Causal graph / Heuristics net
causal_net(eventlog_test)
 
causal_net(eventlog_test, threshold = .7)

causal_net(eventlog_test, threshold = .5)


# petri net 
# Convert to Petri net
cn <- causal_net(eventlog_test, threshold = .7)
pn <- as.petrinet(cn)
render_PN(pn)

```

Visual inspections

```{r}

eventlog_test %>% activity_presence() %>%
    plot

eventlog_test2 %>% 
  process_map(performance())


eventlog_test %>% 
   trace_explorer(n_traces = 10,
                  type = c("frequent"),
                   scale_fill = ggplot2::scale_fill_discrete)

eventlog_test %>% 
   trace_explorer(n_traces = 10,
                  type = c("infrequent"),
                   scale_fill = ggplot2::scale_fill_discrete) # für mich kein unterschied sichtbar zwischen frequent und infrequent 


eventlog_test %>%
    ps_detailed()

```
